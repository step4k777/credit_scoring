# Credit scoring

## Оглавление
1. [Описание проекта](#описание-проекта)
2. [Данные](#данные)
3. [Структура репозитория](#структура-репозитория)
4. [Задача](#задача)
5. [Этапы работы](#этапы-работы)
6. [Модели и результаты](#модели-и-результаты)
7. [Выводы](#выводы)    

### Описание проекта    
Проект посвящён построению модели кредитного скоринга: по данным о заёмщике и его кредитной истории нужно оценить вероятность дефолта по займу.  
Цель проекта — показать полный ML-пайплайн: EDA → предобработка → обучение моделей → сравнение

:arrow_up:[к оглавлению](#Оглавление)

## Данные
- `shift_ml_2026_train.csv` — обучающая выборка (признаки + таргет)
- `shift_ml_2026_test.csv` — тестовая выборка (признаки без таргета)

Размер данных: 1210779 строк и 109 признаков

> Данные не размещены в репозитории (см. `.gitignore`).

:arrow_up:[к оглавлению](#Оглавление)

## Структура репозитория
- `notebooks/01_eda.ipynb` — разведочный анализ данных (EDA)
- `notebooks/02_modeling.ipynb` — предобработка, обучение моделей, сабмит
- `requirements.txt` — зависимости проекта
- `.gitignore` — исключения (данные, сабмиты, временные файлы)

:arrow_up:[к оглавлению](#Оглавление)

## Задача
**Задача бинарной классификации:** предсказать целевой признак `итоговый_статус_займа` (1 - дефолт /0 - не дефолт).  
**Метрика качества:** ROC-AUC.

:arrow_up:[к оглавлению](#Оглавление)

## Этапы работы
1. Импорт библиотек, загрузка данных
2. EDA:
   - анализ целевого признака
   - пропуски и константные признаки
   - базовая статистика и выбросы
3. Предобработка и feature engineering:
   - удаление неинформативных/константных признаков
   - обработка пропусков (фильтрация по порогу + заполнение)
   - кодирование категориальных признаков (BinaryEncoder + OneHot)
   - выравнивание признакового пространства train/test
4. Обучение и сравнение моделей

:arrow_up:[к оглавлению](#Оглавление)

## Модели и результаты
Использовался единый train/valid split с `stratify`, `random_state=42`.

| Модель | ROC-AUC |
|------:|:-------:|
| HistGradientBoostingClassifier | **0.757245** |
| DecisionTreeClassifier | **0.727377** |
| RandomForestClassifier | **0.743123** |

> Итоговая модель для сабмита: HistGradientBoostingClassifier.

:arrow_up:[к оглавлению](#Оглавление)

### Выводы:  

Наилучший результат по метрике ROC-AUC показала модель 
**HistGradientBoostingClassifier (0.757)**.

Градиентный бустинг продемонстрировал более высокое качество по сравнению 
с одиночным деревом решений и случайным лесом, что объясняется способностью 
бустинга последовательно уменьшать ошибки предыдущих моделей и эффективнее 
контролировать смещение и дисперсию.

Сравнение моделей:

Decision Tree < Random Forest < Gradient Boosting

Таким образом, для финального сабмита выбрана модель градиентного бустинга.

:arrow_up:[к оглавлению](#Оглавление)